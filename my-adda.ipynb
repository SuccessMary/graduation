{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Params for ADDA.\"\"\"\n",
    "\n",
    "# # params for dataset and data loader\n",
    "# data_root = \"data\"\n",
    "# dataset_mean_value = 0.5\n",
    "# dataset_std_value = 0.5\n",
    "# dataset_mean = (dataset_mean_value, dataset_mean_value, dataset_mean_value)\n",
    "# dataset_std = (dataset_std_value, dataset_std_value, dataset_std_value)\n",
    "# batch_size = 50\n",
    "# image_size = 64\n",
    "\n",
    "# # params for source dataset 源域数据\n",
    "# src_dataset = \"MNIST\"\n",
    "# src_encoder_restore = \"snapshots/ADDA-source-encoder-final.pt\"\n",
    "# src_classifier_restore = \"snapshots/ADDA-source-classifier-final.pt\"\n",
    "# src_model_trained = True\n",
    "\n",
    "# # params for target dataset 目标域数据\n",
    "# tgt_dataset = \"USPS\"\n",
    "# tgt_encoder_restore = \"snapshots/ADDA-target-encoder-final.pt\"\n",
    "# tgt_model_trained = True\n",
    "\n",
    "# # params for setting up models\n",
    "# model_root = \"snapshots\"\n",
    "# d_input_dims = 500\n",
    "# d_hidden_dims = 500\n",
    "# d_output_dims = 2\n",
    "# d_model_restore = \"snapshots/ADDA-critic-final.pt\"\n",
    "\n",
    "# # params for training network\n",
    "# num_gpu = 1\n",
    "# num_epochs_pre = 100\n",
    "# log_step_pre = 20\n",
    "# eval_step_pre = 20\n",
    "# save_step_pre = 100\n",
    "# num_epochs = 2000\n",
    "# log_step = 100\n",
    "# save_step = 100\n",
    "# manual_seed = None\n",
    "\n",
    "# # params for optimizing models\n",
    "# d_learning_rate = 1e-4\n",
    "# c_learning_rate = 1e-4\n",
    "# beta1 = 0.5\n",
    "# beta2 = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_excel('F:/毕业实验/a3/modal/a3_feature.xlsx',header=0).astype('float32')\n",
    "y = pd.read_excel(r'F:/毕业实验/a3/modal/a3_modal.xlsx',header=0).iloc[:, 1:4].astype('float32')\n",
    "\n",
    "def norm(input):\n",
    "    input_stats = input.describe().transpose()\n",
    "    output = (input - input_stats['mean']) / input_stats['std']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>频率1</th>\n",
       "      <th>阻尼1</th>\n",
       "      <th>质量1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>318.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.98</td>\n",
       "      <td>3.22</td>\n",
       "      <td>439.239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.42</td>\n",
       "      <td>3.52</td>\n",
       "      <td>67.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.45</td>\n",
       "      <td>412.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.14</td>\n",
       "      <td>4.59</td>\n",
       "      <td>210.649994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     频率1   阻尼1         质量1\n",
       "0  16.27  0.50  318.690002\n",
       "1  14.98  3.22  439.239990\n",
       "2  13.42  3.52   67.349998\n",
       "3  13.17  2.45  412.690002\n",
       "4  14.14  4.59  210.649994"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>频率1</th>\n",
       "      <th>阻尼1</th>\n",
       "      <th>质量1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097533</td>\n",
       "      <td>-0.174035</td>\n",
       "      <td>0.118266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.124498</td>\n",
       "      <td>-0.048284</td>\n",
       "      <td>0.261356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.393001</td>\n",
       "      <td>-0.034414</td>\n",
       "      <td>-0.180067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.436030</td>\n",
       "      <td>-0.083882</td>\n",
       "      <td>0.229842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.269076</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>-0.009974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        频率1       阻尼1       质量1\n",
       "0  0.097533 -0.174035  0.118266\n",
       "1 -0.124498 -0.048284  0.261356\n",
       "2 -0.393001 -0.034414 -0.180067\n",
       "3 -0.436030 -0.083882  0.229842\n",
       "4 -0.269076  0.015054 -0.009974"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = scale_related()\n",
    "y_1 = reader.norm(y)\n",
    "y_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>频率1</th>\n",
       "      <td>231.0</td>\n",
       "      <td>15.703334</td>\n",
       "      <td>1.034761</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>15.050000</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>16.515000</td>\n",
       "      <td>18.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>阻尼1</th>\n",
       "      <td>231.0</td>\n",
       "      <td>4.264372</td>\n",
       "      <td>1.573759</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>4.070000</td>\n",
       "      <td>4.795000</td>\n",
       "      <td>22.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>质量1</th>\n",
       "      <td>231.0</td>\n",
       "      <td>219.053085</td>\n",
       "      <td>122.385483</td>\n",
       "      <td>67.349998</td>\n",
       "      <td>158.560005</td>\n",
       "      <td>185.699997</td>\n",
       "      <td>234.639999</td>\n",
       "      <td>909.830017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     count        mean         std        min         25%         50%  \\\n",
       "频率1  231.0   15.703334    1.034761  12.460000   15.050000   15.750000   \n",
       "阻尼1  231.0    4.264372    1.573759   0.450000    3.550000    4.070000   \n",
       "质量1  231.0  219.053085  122.385483  67.349998  158.560005  185.699997   \n",
       "\n",
       "            75%         max  \n",
       "频率1   16.515000   18.270000  \n",
       "阻尼1    4.795000   22.080000  \n",
       "质量1  234.639999  909.830017  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>频率1</th>\n",
       "      <th>阻尼1</th>\n",
       "      <th>质量1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>318.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.98</td>\n",
       "      <td>3.22</td>\n",
       "      <td>439.239990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.42</td>\n",
       "      <td>3.52</td>\n",
       "      <td>67.349991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.45</td>\n",
       "      <td>412.690002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.14</td>\n",
       "      <td>4.59</td>\n",
       "      <td>210.649994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     频率1   阻尼1         质量1\n",
       "0  16.27  0.50  318.690002\n",
       "1  14.98  3.22  439.239990\n",
       "2  13.42  3.52   67.349991\n",
       "3  13.17  2.45  412.690002\n",
       "4  14.14  4.59  210.649994"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2 = y_1 * (reader.stats['max'] - reader.stats['min']) + reader.stats['mean']\n",
    "y_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机生成目标域的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class scale_related():\n",
    "    def __init__(self):\n",
    "        self.stats = []\n",
    "        self.input = None\n",
    "    def norm(self,x):\n",
    "        self.input = x\n",
    "        self.stats = self.input.describe().transpose()\n",
    "        output = (self.input - self.stats['mean']) / (self.stats['max'] - self.stats['min'])\n",
    "        return output\n",
    "#     def inverse_norm(self,x):\n",
    "#         print(self.stats)\n",
    "#         self.input = x\n",
    "#         out_put = x * (self.stats['max'] - self.stats['min']) + self.stats['mean']\n",
    "#         return out_put\n",
    "#     def Normalize(self,y):\n",
    "#         self.norm_y[0,0] = np.average(y)\n",
    "#         self.norm_y[0,1] = np.max(y) - np.min(y)\n",
    "#         return (y - self.norm[0,0]) / self.norm_y[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def get_target_data_loader():\n",
    "    x = pd.read_excel('F:/毕业实验/a3/modal/a3_feature.xlsx',header=0).astype('float32')\n",
    "    x = scale_related().norm(x)\n",
    "    y = pd.read_excel(r'F:/毕业实验/a3/modal/a3_modal.xlsx',header=0).iloc[:, 1:4].astype('float32')\n",
    "    y = scale_related().norm(y)\n",
    "    trn_x, val_x, trn_y, val_y = train_test_split(x, y, test_size=0.2)\n",
    "    trn_x = torch.from_numpy(np.array(trn_x))\n",
    "    trn_y = torch.from_numpy(np.array(trn_y))\n",
    "    val_x = torch.from_numpy(np.array(val_x))\n",
    "    val_y = torch.from_numpy(np.array(val_y))\n",
    "    \n",
    "\n",
    "    #x扩充至三维,原来的【314*9】转变为【314*1*9】\n",
    "    trn_x = torch.unsqueeze(trn_x, 1)\n",
    "    val_x = torch.unsqueeze(val_x, 1)\n",
    "    print(trn_x.shape,trn_y.shape,val_x.shape,val_y.shape)\n",
    "    # #y减少至一维\n",
    "    # source_y = torch.squeeze(source_y, 1)\n",
    "    # target_y = torch.squeeze(target_y, 1)\n",
    "\n",
    "    #运用批训练，装进loder里\n",
    "    trn_data = Data.TensorDataset(trn_x, trn_y)\n",
    "    val_data = Data.TensorDataset(val_x, val_y)\n",
    "\n",
    "    trn_data_loder = Data.DataLoader(dataset=trn_data,\n",
    "                                      batch_size=params.batch_size,\n",
    "                                      shuffle=True\n",
    "                                     )\n",
    "    val_data_loder = Data.DataLoader(dataset=val_data,\n",
    "                                      batch_size=params.batch_size,\n",
    "                                      shuffle=True\n",
    "                                     )\n",
    "    return (trn_data_loder,val_data_loder)\n",
    "\n",
    "\n",
    "def get_source_data_loader(): \n",
    "#     x = torch.from_numpy(StandardScaler().fit_transform(np.random.rand(200,9))).float()\n",
    "\n",
    "    x = pd.read_excel('F:/毕业实验/a1/processed modal/a1_feature.xlsx',header=0).astype('float32')\n",
    "    x = scale_related().norm(x)\n",
    "    x =  torch.from_numpy(np.array(x))\n",
    "    x = torch.unsqueeze(x,1)\n",
    "    \n",
    "    y = pd.read_excel('F:/毕业实验/a1/processed modal/a1_modal_15-23-2.xlsx',header=0).iloc[:, 1:].astype('float32')\n",
    "    y = scale_related().norm(y)\n",
    "    y = torch.from_numpy(np.array(y))\n",
    "    \n",
    "    trn_x,val_x,trn_y,val_y = train_test_split(x,y,test_size=0.2)\n",
    "    print(trn_x.shape,trn_x.shape,val_x.shape,val_y.shape)\n",
    "        \n",
    "    trn_data = Data.TensorDataset(trn_x,trn_y)\n",
    "    trn_data_loder = Data.DataLoader(dataset=trn_data,\n",
    "                                         batch_size=50,\n",
    "                                         shuffle=True\n",
    "                                        )\n",
    "    val_data = Data.TensorDataset(val_x,val_y)\n",
    "    val_data_loder = Data.DataLoader(dataset=val_data,\n",
    "                                         batch_size=50,\n",
    "                                         shuffle=True\n",
    "                                        )\n",
    "    \n",
    "    return (trn_data_loder,val_data_loder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import params\n",
    "from core import eval_src, eval_tgt, train_src, train_tgt\n",
    "from models import Discriminator, LeNetRegressor, LeNetEncoder\n",
    "from utils import get_data_loader, init_model, init_random_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use random seed: 2020\n",
      "torch.Size([620, 1, 8]) torch.Size([620, 1, 8]) torch.Size([155, 1, 8]) torch.Size([155, 3])\n",
      "torch.Size([184, 1, 8]) torch.Size([184, 3]) torch.Size([47, 1, 8]) torch.Size([47, 3])\n"
     ]
    }
   ],
   "source": [
    "# init random seed\n",
    "init_random_seed(params.manual_seed)\n",
    "\n",
    "# load dataset加载数据\n",
    "# src_data_loader = get_data_loader(params.src_dataset)\n",
    "# src_data_loader_eval = get_data_loader(params.src_dataset, train=False)\n",
    "# tgt_data_loader = get_data_loader(params.tgt_dataset)\n",
    "# tgt_data_loader_eval = get_data_loader(params.tgt_dataset, train=False)\n",
    "src_data_loader, src_data_loader_eval = get_source_data_loader()\n",
    "tgt_data_loader, tgt_data_loader_eval = get_target_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 184\n"
     ]
    }
   ],
   "source": [
    "print(len(tgt_data_loader),len(tgt_data_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载各模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore model from: D:\\个人资料\\研究生\\机器学习\\Jupyter\\迁移学习练习赛-2\\run\\snapshots\\ADDA-source-encoder-final.pt\n",
      "Restore model from: D:\\个人资料\\研究生\\机器学习\\Jupyter\\迁移学习练习赛-2\\run\\snapshots\\ADDA-source-classifier-final.pt\n",
      "Restore model from: D:\\个人资料\\研究生\\机器学习\\Jupyter\\迁移学习练习赛-2\\run\\snapshots\\ADDA-target-encoder-final.pt\n",
      "Restore model from: D:\\个人资料\\研究生\\机器学习\\Jupyter\\迁移学习练习赛-2\\run\\snapshots\\ADDA-critic-final.pt\n"
     ]
    }
   ],
   "source": [
    "# load models\n",
    "src_encoder = init_model(net=LeNetEncoder(),\n",
    "                             restore=params.src_encoder_restore)\n",
    "src_classifier = init_model(net=LeNetRegressor(),\n",
    "                                restore=params.src_classifier_restore)\n",
    "tgt_encoder = init_model(net=LeNetEncoder(),\n",
    "                             restore=params.tgt_encoder_restore)\n",
    "critic = init_model(Discriminator(input_dims=params.d_input_dims,\n",
    "                                      hidden_dims=params.d_hidden_dims,\n",
    "                                      output_dims=params.d_output_dims),\n",
    "                        restore=params.d_model_restore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练源域回归器和源域映射器（也称编码器）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training classifier for source domain ===\n",
      ">>> Source Encoder <<<\n",
      "LeNetEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv1d(1, 20, kernel_size=(3,), stride=(1,))\n",
      "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Conv1d(20, 50, kernel_size=(3,), stride=(1,))\n",
      "    (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): LeakyReLU(negative_slope=0.01)\n",
      "    (7): Conv1d(50, 100, kernel_size=(3,), stride=(1,))\n",
      "    (8): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
      ")\n",
      ">>> Source Classifier <<<\n",
      "LeNetRegressor(\n",
      "  (fc2): Linear(in_features=100, out_features=3, bias=True)\n",
      ")\n",
      "=== Evaluating classifier for source domain ===\n",
      "Avg loss1: 247.03182983398438, Avg loss2: 14.112746715545654, Avg loss3: 71725.58203125\n",
      "Avg Acc1: 239.16839599609375, Avg Acc2: 13.8157320022583, Avg Acc3: 76415.390625\n"
     ]
    }
   ],
   "source": [
    "# train source model\n",
    "print(\"=== Training classifier for source domain ===\")\n",
    "print(\">>> Source Encoder <<<\")\n",
    "print(src_encoder)\n",
    "print(\">>> Source Classifier <<<\")\n",
    "print(src_classifier)\n",
    "\n",
    "if not (src_encoder.restored and src_classifier.restored and\n",
    "            params.src_model_trained):  #如果都没有存储，意为都没有开始训练，所以先训练源域的分类器和编码器\n",
    "    src_encoder, src_classifier = train_src(\n",
    "            src_encoder, src_classifier, src_data_loader)\n",
    "\n",
    "# eval source model 对源域的两个模型做测评\n",
    "print(\"=== Evaluating classifier for source domain ===\")\n",
    "eval_src(src_encoder, src_classifier, src_data_loader_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行对抗生成部分的训练\n",
    "\n",
    "输出的是经过GAN思想训练后的目标域编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training encoder for target domain ===\n",
      ">>> Target Encoder <<<\n",
      "LeNetEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv1d(1, 20, kernel_size=(3,), stride=(1,))\n",
      "    (1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.01)\n",
      "    (3): Conv1d(20, 50, kernel_size=(3,), stride=(1,))\n",
      "    (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): LeakyReLU(negative_slope=0.01)\n",
      "    (7): Conv1d(50, 100, kernel_size=(3,), stride=(1,))\n",
      "    (8): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
      ")\n",
      ">>> Critic <<<\n",
      "Discriminator(\n",
      "  (layer): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=40, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=40, out_features=40, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=40, out_features=2, bias=True)\n",
      "    (5): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train target encoder by GAN\n",
    "print(\"=== Training encoder for target domain ===\")\n",
    "print(\">>> Target Encoder <<<\")\n",
    "print(tgt_encoder)\n",
    "print(\">>> Critic <<<\")\n",
    "print(critic)\n",
    "\n",
    "# init weights of target encoder with those of source encoder 源域编码器和目标域编码器共用参数\n",
    "#如果目标域分类器没训练，就加载已训练的源域分类器的参数到未训练的目标域分类器\n",
    "if not tgt_encoder.restored:   \n",
    "    tgt_encoder.load_state_dict(src_encoder.state_dict())\n",
    "\n",
    "if not (tgt_encoder.restored and critic.restored and   #如果目标域编码器、域分类器都没训练，就开始训练\n",
    "            params.tgt_model_trained):\n",
    "    tgt_encoder = train_tgt(src_encoder, tgt_encoder, critic,\n",
    "                                src_data_loader, tgt_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试经过GAN思想训练后的目标域编码器对目标域数据的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating classifier for encoded target domain ===\n",
      ">>> source encoder only <<<\n",
      "Avg loss1: 231.44818115234375, Avg loss2: 12.96254825592041, Avg loss3: 65547.4140625\n",
      "Avg Acc1: 231.44818115234375, Avg Acc2: 12.96254825592041, Avg Acc3: 65547.4140625\n",
      ">>> domain adaption with train data of target area<<<\n",
      "Avg loss1: 122.09300994873047, Avg loss2: 9.08135449886322, Avg loss3: 45582.962890625\n",
      "Avg Acc1: 120.42388153076172, Avg Acc2: 8.946013450622559, Avg Acc3: 44481.65625\n",
      ">>> domain adaption with valid data of target area<<<\n",
      "Avg loss1: 130.89271545410156, Avg loss2: 9.840137481689453, Avg loss3: 50852.46875\n",
      "Avg Acc1: 130.89273071289062, Avg Acc2: 9.840136528015137, Avg Acc3: 50852.4609375\n"
     ]
    }
   ],
   "source": [
    "# eval target encoder on test set of target dataset\n",
    "print(\"=== Evaluating classifier for encoded target domain ===\")\n",
    "print(\">>> source encoder only <<<\")\n",
    "eval_tgt(src_encoder, src_classifier, tgt_data_loader_eval)\n",
    "print(\">>> domain adaption with train data of target area<<<\")\n",
    "eval_tgt(tgt_encoder, src_classifier, tgt_data_loader)\n",
    "print(\">>> domain adaption with valid data of target area<<<\")\n",
    "eval_tgt(tgt_encoder, src_classifier, tgt_data_loader_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-e874f3fb6f0a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-e874f3fb6f0a>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    === Evaluating classifier for encoded target domain ===\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "num_epcho_pre:100\n",
    "num_epcho:2000\n",
    "d_learning_rate = 1e-4\n",
    "c_learning_rate = 1e-4\n",
    "=== Evaluating classifier for encoded target domain ===\n",
    ">>> source data only <<<\n",
    "Avg loss1: 0.03473568335175514, Avg loss2: 0.0048118713311851025, Avg loss3: 0.01357198040932417\n",
    "Avg Acc1: 0.03473568335175514, Avg Acc2: 0.0048118713311851025, Avg Acc3: 0.01357197854667902\n",
    ">>> domain adaption with train data of target area<<<\n",
    "Avg loss1: 0.12997924350202084, Avg loss2: 0.010026364238001406, Avg loss3: 0.0328241758979857\n",
    "Avg Acc1: 0.1292630434036255, Avg Acc2: 0.010212046094238758, Avg Acc3: 0.03152913972735405\n",
    ">>> domain adaption with valid data of target area<<<\n",
    "Avg loss1: 0.1360187530517578, Avg loss2: 0.006971478927880526, Avg loss3: 0.02592497132718563\n",
    "Avg Acc1: 0.1360187530517578, Avg Acc2: 0.0069714798592031, Avg Acc3: 0.02592497132718563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epcho_pre:100\n",
    "num_epcho:2000\n",
    "d_learning_rate = 1e-4\n",
    "c_learning_rate = 1e-4\n",
    "seed = ?\n",
    "\n",
    ">>> source data only <<<\n",
    "Avg loss1: 761.9774780273438, Avg loss2: 114.5185317993164, Avg loss3: 152790.375\n",
    "Avg Acc1: 48.63685989379883, Avg Acc2: 7.309693813323975, Avg Acc3: 9752.5771484375\n",
    ">>> domain adaption <<<\n",
    "Avg loss1: 1405.0460205078125, Avg loss2: 57.5964241027832, Avg loss3: 1592.2642822265625\n",
    "Avg Acc1: 89.68379211425781, Avg Acc2: 3.6763675212860107, Avg Acc3: 101.63389587402344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epcho_pre:200\n",
    "num_epcho:3000\n",
    "d_learning_rate = 1e-4\n",
    "c_learning_rate = 1e-4\n",
    "seed = 2020\n",
    "\n",
    ">>> source data only <<<\n",
    "Avg loss1: 10.734519004821777, Avg loss2: 10.35787296295166, Avg loss3: 35074.77734375\n",
    "Avg Acc1: 10.734518051147461, Avg Acc2: 10.357874870300293, Avg Acc3: 35074.77734375\n",
    ">>> domain adaption with train data of target area<<<\n",
    "Avg loss1: 37.8518762588501, Avg loss2: 12.12198257446289, Avg loss3: 16702.656494140625\n",
    "Avg Acc1: 37.88945388793945, Avg Acc2: 11.20166301727295, Avg Acc3: 17031.376953125\n",
    ">>> domain adaption with valid data of target area<<<\n",
    "Avg loss1: 38.251564025878906, Avg loss2: 8.086509704589844, Avg loss3: 18772.818359375\n",
    "Avg Acc1: 38.25156021118164, Avg Acc2: 8.08651065826416, Avg Acc3: 18772.81640625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_data = torch.FloatTensor(2,3)\n",
    "# 保存数据\n",
    "torch.save(test_data, \"test_data.pkl\")\n",
    "\n",
    "print(test_data)\n",
    "# 提取数据\n",
    "print(torch.load(\"test_data.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.floor(5/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
